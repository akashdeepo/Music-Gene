{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define Music Theory Elements\n",
    "# Define frequencies for the C Major, G Major, and A Minor scales (in Hz)\n",
    "c_major_scale = [261.63, 293.66, 329.63, 349.23, 392.00, 440.00, 493.88, 523.25]  # C4 to C5\n",
    "g_major_scale = [392.00, 440.00, 493.88, 523.25, 587.33, 659.25, 739.99, 783.99]  # G4 to G5\n",
    "a_minor_scale = [220.00, 246.94, 261.63, 293.66, 329.63, 349.23, 392.00, 440.00]  # A3 to A4\n",
    "\n",
    "# Chord progressions in C Major, G Major, and A Minor\n",
    "chord_progressions = {\n",
    "    \"I-IV-V\": [[261.63, 329.63, 392.00], [349.23, 440.00, 523.25], [392.00, 493.88, 261.63]],  # C-F-G\n",
    "    \"ii-V-I\": [[293.66, 349.23, 440.00], [392.00, 493.88, 261.63], [261.63, 329.63, 392.00]],  # Dm-G-C\n",
    "    \"vi-IV-I-V\": [[220.00, 293.66, 349.23], [349.23, 440.00, 523.25], [261.63, 329.63, 392.00], [392.00, 493.88, 261.63]]  # Am-F-C-G\n",
    "}\n",
    "\n",
    "# Durations (in seconds)\n",
    "durations = [0.25, 0.5, 0.75, 1.0]  # Quarters, halves, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Generate a Complex Music Theory-Inspired Dataset\n",
    "def generate_complex_music_sequence(scales, chord_progressions, num_sequences=5):\n",
    "    dataset = []\n",
    "    for _ in range(num_sequences):\n",
    "        sequence = []\n",
    "        current_scale = random.choice(scales)\n",
    "        for _ in range(random.randint(16, 32)):  # Longer sequences for more depth\n",
    "            progression_type = random.random()\n",
    "            if progression_type < 0.4:  # 40% chance of a scale note\n",
    "                note = random.choice(current_scale)\n",
    "                duration = random.choice(durations)\n",
    "                sequence.append((note, duration))\n",
    "            elif progression_type < 0.7:  # 30% chance of a chord progression\n",
    "                chord = random.choice(list(chord_progressions.values()))\n",
    "                duration = random.choice(durations)\n",
    "                sequence.append((chord, duration))\n",
    "            elif progression_type < 0.9:  # 20% chance of modulation\n",
    "                current_scale = random.choice(scales)\n",
    "            else:  # 10% chance of dynamic change or rest\n",
    "                if random.random() < 0.5:\n",
    "                    note = random.choice(current_scale)\n",
    "                    duration = random.choice(durations) * 2  # Longer note for intensity\n",
    "                    sequence.append((note, duration))\n",
    "                else:\n",
    "                    # Introduce a rest (silence)\n",
    "                    sequence.append((0, random.choice(durations)))  # 0 frequency for rest\n",
    "        dataset.append(sequence)\n",
    "    return dataset\n",
    "\n",
    "# Define different scales\n",
    "scales = [c_major_scale, g_major_scale, a_minor_scale]\n",
    "\n",
    "# Generate the complex dataset\n",
    "complex_music_theory_dataset = generate_complex_music_sequence(scales, chord_progressions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Preprocess Function with Chord Averaging\n",
    "def preprocess_dataset(dataset):\n",
    "    flat_notes, flat_durations = [], []\n",
    "    \n",
    "    for sequence in dataset:\n",
    "        for element in sequence:\n",
    "            note, duration = element[0], element[1]\n",
    "            \n",
    "            if isinstance(note, list):  # If it's a chord\n",
    "                average_note = np.mean(note)  # Take the average frequency of the chord\n",
    "                flat_notes.append(average_note)\n",
    "                flat_durations.append(duration)\n",
    "            elif isinstance(note, (int, float)):  # It's already a single note\n",
    "                flat_notes.append(note)\n",
    "                flat_durations.append(duration)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected note type: {type(note)} with value {note}\")\n",
    "                \n",
    "    return np.array(flat_notes).reshape(-1, 1), np.array(flat_durations).reshape(-1, 1)\n",
    "\n",
    "# Generate the notes and durations arrays\n",
    "notes, durations = preprocess_dataset(complex_music_theory_dataset)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "notes_scaled = scaler.fit_transform(notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 3s 20ms/step - loss: 0.2636\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0984\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0521\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0689\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0408\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0473\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0519\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0488\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0447\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0416\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0420\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0446\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0407\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0430\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0403\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0404\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0423\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0404\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0399\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0415\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0412\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0412\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0392\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0401\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0399\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0418\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0442\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0404\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0428\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0438\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0430\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0431\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0407\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0417\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0419\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0420\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0413\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0451\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0399\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0409\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0420\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0392\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0418\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0399\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0403\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0404\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0410\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0422\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0425\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0405\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0408\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0431\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0389\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0401\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0438\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0394\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0403\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0442\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0448\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0400\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0411\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0416\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0394\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0415\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0414\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0389\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0398\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0412\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0408\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0402\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0405\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0413\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0403\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0400\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0414\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0416\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0395\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0422\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0382\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0411\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0414\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0418\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0386\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0406\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0405\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0403\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0403\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0409\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0407\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0400\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0372\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0397\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0409\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0394\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0391\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0402\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0410\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0407\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0387\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x213b32ba470>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Build and Train the LSTM Model\n",
    "# Prepare data for LSTM\n",
    "sequence_length = 16\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(notes_scaled) - sequence_length):\n",
    "    X.append(notes_scaled[i:i + sequence_length])\n",
    "    y.append(notes_scaled[i + sequence_length])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(sequence_length, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define Functions for Music Generation and Conversion\n",
    "# Function to generate a square wave for 8-bit sound\n",
    "def generate_square_wave(frequency, duration, sample_rate=44100, amplitude=0.5):\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    wave = amplitude * np.sign(np.sin(2 * np.pi * frequency * t))\n",
    "    return wave\n",
    "\n",
    "# Create the audio file from the generated sequence\n",
    "def create_8bit_music_clip(sequence, sample_rate=44100, apply_counter_melody=False):\n",
    "    music = AudioSegment.silent(duration=0)  # Start with silence\n",
    "    counter_melody = []\n",
    "    \n",
    "    for element in sequence:\n",
    "        note, duration = element[0], element[1]\n",
    "        if isinstance(note, list):  # Handle chords\n",
    "            chord_wave = sum(generate_square_wave(n, duration, sample_rate) for n in note) / len(note)\n",
    "            audio = np.int16(chord_wave * 32767)\n",
    "            if apply_counter_melody:\n",
    "                counter_note = random.choice(note) * 1.5  # Simple counter melody one octave higher\n",
    "                counter_melody.append((counter_note, duration))\n",
    "        else:\n",
    "            wave = generate_square_wave(note, duration, sample_rate)\n",
    "            audio = np.int16(wave * 32767)\n",
    "            if apply_counter_melody:\n",
    "                counter_note = note * 1.5\n",
    "                counter_melody.append((counter_note, duration))\n",
    "        \n",
    "        note_segment = AudioSegment(\n",
    "            audio.tobytes(), \n",
    "            frame_rate=sample_rate, \n",
    "            sample_width=2, \n",
    "            channels=1\n",
    "        )\n",
    "        music += note_segment  # Append each note's segment to the music\n",
    "    \n",
    "    # Add counter-melody if applicable\n",
    "    if apply_counter_melody:\n",
    "        counter_melody_audio = create_8bit_music_clip(counter_melody, sample_rate=False)\n",
    "        music = music.overlay(counter_melody_audio)\n",
    "    \n",
    "    return music\n",
    "\n",
    "# Function to generate a 20-second music sequence\n",
    "def generate_music(model, seed_sequence, num_notes, scaler):\n",
    "    generated_sequence = seed_sequence\n",
    "    for _ in range(num_notes):\n",
    "        X_input = generated_sequence[-sequence_length:].reshape(1, sequence_length, 1)\n",
    "        prediction = model.predict(X_input, verbose=0)\n",
    "        generated_sequence = np.vstack([generated_sequence, prediction])\n",
    "    return scaler.inverse_transform(generated_sequence).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated and saved 'nuanced_8bit_music_clip_1.wav'\n",
      "Generated and saved 'nuanced_8bit_music_clip_2.wav'\n",
      "Generated and saved 'nuanced_8bit_music_clip_3.wav'\n",
      "Generated and saved 'nuanced_8bit_music_clip_4.wav'\n",
      "Generated and saved 'nuanced_8bit_music_clip_5.wav'\n"
     ]
    }
   ],
   "source": [
    "# Updated function to ensure different start sequences\n",
    "def generate_and_save_nuanced_clips(model, dataset, num_clips=5, clip_duration=10, sample_rate=44100):\n",
    "    for i in range(num_clips):\n",
    "        # Select a random sequence from the dataset as a seed\n",
    "        random_start_index = random.randint(0, len(dataset) - 1)\n",
    "        seed_sequence = np.array(preprocess_dataset([dataset[random_start_index]])[0]).reshape(-1, 1)\n",
    "        \n",
    "        # Ensure the seed sequence length matches the LSTM input sequence length\n",
    "        if seed_sequence.shape[0] < sequence_length:\n",
    "            seed_sequence = np.pad(seed_sequence, ((0, sequence_length - seed_sequence.shape[0]), (0, 0)), 'constant')\n",
    "        else:\n",
    "            seed_sequence = seed_sequence[:sequence_length]\n",
    "        \n",
    "        # Generate the number of notes based on the desired clip duration\n",
    "        num_notes = int(clip_duration / random.choice(durations))\n",
    "        generated_notes = generate_music(model, seed_sequence, num_notes, scaler)\n",
    "        \n",
    "        # Create an 8-bit music clip with more complexity\n",
    "        clip = create_8bit_music_clip(list(zip(generated_notes, [0.5] * num_notes)), apply_counter_melody=True)\n",
    "        clip_name = f\"nuanced_8bit_music_clip_{i+1}.wav\"\n",
    "        clip.export(clip_name, format=\"wav\")\n",
    "        print(f\"Generated and saved '{clip_name}'\")\n",
    "\n",
    "# Generate and save 5 nuanced clips\n",
    "generate_and_save_nuanced_clips(model, complex_music_theory_dataset, num_clips=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
